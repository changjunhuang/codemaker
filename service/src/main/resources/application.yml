#Tomcat
server:
  port: 8080

# Spring
spring:
  application:
    name: codemaker-service

  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    druid: ## druid数据库连接池的基本初始化属性
      initial-size: 5 # 连接池初始化的大小
      min-idle: 1 # 最小空闲的线程数
      max-active: 20 # 最大活动的线程数

    mysql-master: ## 主库写
      driver-class-name: com.mysql.cj.jdbc.Driver
      jdbc-url: jdbc:mysql://localhost:3306/self_test?useUnicode=true&characterEncoding=UTF-8&serverTimezone=UTC
      username: root
      password: 10010hcj

    mysql-slave:  ## 从库读
      driver-class-name: com.mysql.cj.jdbc.Driver
      jdbc-url: jdbc:mysql://localhost:3306/duplicate_db?useUnicode=true&characterEncoding=UTF-8&serverTimezone=UTC
      username: root
      password: 10010hcj

# Redis
  redis:
    host: 127.0.0.1 #单机配置
    post: 6379 #单机配置
    password:
    #    cluster: #集群配置
    #      host:
    timeout: 1000
    database: 0
    lettuce:
      pool:
        max-active: 8  # 连接池最大连接数 默认8 ，负数表示没有限制
        max-idle: 8  # 连接池中的最大空闲连接 默认8
        max-wait: -1 # 连接池最大阻塞等待时间（使用负值表示没有限制） 默认-1
        min-idle: 0  # 连接池中的最小空闲连接 默认0

# Kafka
  kafka:
    bootstrap-servers: 127.0.0.1:9092  # Kafka的服务器地址
    listener:
      missing-topics-fatal: false
    producer: # producer 生产者
      retries: 0 # 重试次数
      acks: 1 # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
      batch-size: 16384 # 批量大小
      buffer-memory: 33554432 # 生产端缓冲区大小
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      #      value-serializer: com.itheima.demo.config.MySerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer

    consumer: # consumer消费者
      group-id: kafka-group # 默认的消费组ID
      enable-auto-commit: true # 是否自动提交offset
      auto-commit-interval: 100  # 提交offset延时(接收到消息后多久提交offset)

      # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: latest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #      value-deserializer: com.itheima.demo.config.MyDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

# Mybatis
mybatis-plus:
  mapper-locations: classpath*:/mybatis/mapper/*.xml,/mybatis/*.xml  # 配置MyBatis-Plus扫描Mapper文件的位置
  type-aliases-package: com.self.codemaker.model  # 创建别名的类所在的包
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #开启sql日志
    map-underscore-to-camel-case: true  # 该配置就是将带有下划线的表字段映射为驼峰格式的实体类属性


# Eureka
eureka:
  client:
    service-url:
      defaultZone: http://localhost:8088/eureka

# log
logging:
  pattern:
    console: '%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread]%-5level-%highlight(%C-%M:%L)-%msg%n'
  level:
    com.self.codemaker.dao: DEBUG # 包路径为mapper文件包路径